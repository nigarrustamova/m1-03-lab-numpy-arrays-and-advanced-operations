{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96e510ce-4409-4ddb-8f93-4fadc84d15ef",
   "metadata": {},
   "source": [
    "# Task 1: Generate a reproducible sensor matrix\n",
    "Create a 2D NumPy array named readings with shape (360, 4) to represent six hours of minute-level readings from four sensors. Use a fixed seed and generate values that roughly follow a normal distribution around 50 with some variation. After creating the array, print its shape, dtype, and the first three rows to confirm the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8f7a967-2a8b-4406-b944-2dde45f9657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "readings = rng.normal(50, 10, size=(360, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758b0b45-6131-40b5-beb9-4a14d0d8f754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51.25730221, 48.67895137, 56.4042265 , 51.04900117],\n",
       "       [44.64330627, 53.61595055, 63.04000045, 59.47080963],\n",
       "       [42.96264764, 37.34578529, 43.76725537, 50.41325979],\n",
       "       ...,\n",
       "       [43.66139802, 52.96379038, 47.42410516, 36.32827186],\n",
       "       [49.73843213, 65.95702441, 70.02532317, 44.3295854 ],\n",
       "       [59.05274604, 51.32529455, 52.8388663 , 62.67371213]],\n",
       "      shape=(360, 4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc49f42-fa8e-48fd-ae84-3c40ee15395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 4)\n"
     ]
    }
   ],
   "source": [
    "print(readings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf68decf-4809-424b-a98d-346b1648a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(readings.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b87b33e-db27-4ff4-aeae-dcecb88ae278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[51.25730221 48.67895137 56.4042265  51.04900117]\n",
      " [44.64330627 53.61595055 63.04000045 59.47080963]\n",
      " [42.96264764 37.34578529 43.76725537 50.41325979]]\n"
     ]
    }
   ],
   "source": [
    "print(readings[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49afb5b1-c319-47ab-89b8-5c188f824ef2",
   "metadata": {},
   "source": [
    "# Task 2: Apply vectorized transformations\n",
    "Create a new array scaled_readings that rescales the original readings to a 0â€“1 range using vectorized operations. Do not use loops. Then create a second array centered_readings by subtracting the column means from the original readings. Verify both arrays have the same shape as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0841b14d-959d-4a16-9b76-268e94ba8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "readings_min = readings.min()\n",
    "readings_max = readings.max()\n",
    "\n",
    "scaled_readings = (readings - readings_min) / (readings_max - readings_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7c86a84-e1b7-423f-b40d-96140d0909f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = readings.mean(axis=0)\n",
    "centered_readings = readings - column_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56907b2-17f5-49b0-9f0c-2d1a9493f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (360, 4)\n",
      "Scaled shape:    (360, 4)\n",
      "Centered shape:  (360, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shape:  {readings.shape}\")\n",
    "print(f\"Scaled shape:    {scaled_readings.shape}\")\n",
    "print(f\"Centered shape:  {centered_readings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4a107-c968-47d5-bfab-3e4ff02a77e0",
   "metadata": {},
   "source": [
    "# Task 3: Filter outliers with boolean masks\n",
    "Define outliers as any reading above 80 or below 20. Build a boolean mask that identifies outliers across the full matrix. Use the mask to compute two values: the count of outlier readings and the percentage of total readings that are outliers. Then create a cleaned array cleaned_readings where outliers are replaced with np.nan. Confirm that the number of np.nan values matches your outlier count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ac895e6-114d-4de5-9eeb-83d5e255f714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier Count: 5\n",
      "Outlier Percentage: 0.35%\n",
      "Number of NaNs in cleaned array: 5\n",
      "Verification Match: True\n"
     ]
    }
   ],
   "source": [
    "outlier_mask = (readings > 80) | (readings < 20)\n",
    "\n",
    "outlier_count = np.sum(outlier_mask)\n",
    "total_elements = readings.size\n",
    "outlier_percentage = (outlier_count / total_elements) * 100\n",
    "\n",
    "cleaned_readings = readings.copy()\n",
    "cleaned_readings[outlier_mask] =np.nan\n",
    "\n",
    "nan_count = np.isnan(cleaned_readings).sum()\n",
    "\n",
    "print(f\"Outlier Count: {outlier_count}\")\n",
    "print(f\"Outlier Percentage: {outlier_percentage:.2f}%\")\n",
    "print(f\"Number of NaNs in cleaned array: {nan_count}\")\n",
    "print(f\"Verification Match: {outlier_count == nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e9a9bd-3fe5-4873-9ea3-e8d55d8cf643",
   "metadata": {},
   "source": [
    "# Task 4: Compute summaries by sensor and over time\n",
    "Compute the mean and standard deviation for each sensor using axis-based aggregation. Store the results in two 1D arrays named sensor_means and sensor_stds. Then compute the average reading at each time step across sensors and store it in a 1D array named time_means. Validate shapes: the sensor summaries should have length 4, and the time summary should have length 360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b31dc86f-5566-4fde-8778-4242603418b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor Means shape: (4,)\n",
      "Sensor Stds shape:  (4,)\n",
      "Time Means shape:   (360,)\n"
     ]
    }
   ],
   "source": [
    "sensor_means = readings.mean(axis=0)\n",
    "sensor_stds = readings.std(axis=0)\n",
    "\n",
    "time_means = readings.mean(axis=1)\n",
    "\n",
    "print(f\"Sensor Means shape: {sensor_means.shape}\")\n",
    "print(f\"Sensor Stds shape:  {sensor_stds.shape}\")\n",
    "print(f\"Time Means shape:   {time_means.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82f6cd-549d-4e75-8f36-af47f922951a",
   "metadata": {},
   "source": [
    "# Task 5: Build a validation report (Part 1)\n",
    "Create a short report dictionary with keys total_readings, outlier_count, outlier_percent, sensor_means, and sensor_stds. Convert this report into a readable string and print it in the notebook. Include at least one simple validation, such as confirming that total_readings equals readings.size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55d689b9-09cc-42b9-8a41-bd91c76ea3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    \"total_readings\": readings.size,\n",
    "    \"outlier_count\": outlier_count,\n",
    "    \"outlier_percent\": outlier_percentage,\n",
    "    \"sensor_means\": sensor_means,\n",
    "    \"sensor_stds\": sensor_stds\n",
    "}\n",
    "is_valid = report[\"total_readings\"] == readings.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c751cb6-3dcd-457a-8d0f-c6418986f740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SENSOR DATA VALIDATION REPORT ---\n",
      "Total Readings:     1440\n",
      "Validation Status:  PASS\n",
      "\n",
      "Outlier Count:      5\n",
      "Outlier Percentage: 0.35%\n",
      "\n",
      "Sensor Means:       [49.84 49.3  49.37 51.  ]\n",
      "Sensor Std Devs:    [ 9.75  9.59 10.   10.19]\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_string = f\"\"\"\n",
    "--- SENSOR DATA VALIDATION REPORT ---\n",
    "Total Readings:     {report['total_readings']}\n",
    "Validation Status:  {'PASS' if is_valid else 'FAIL'}\n",
    "\n",
    "Outlier Count:      {report['outlier_count']}\n",
    "Outlier Percentage: {report['outlier_percent']:.2f}%\n",
    "\n",
    "Sensor Means:       {np.round(report['sensor_means'], 2)}\n",
    "Sensor Std Devs:    {np.round(report['sensor_stds'], 2)}\n",
    "-------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff01fb-6976-4660-b7cd-8c0db0de2ad9",
   "metadata": {},
   "source": [
    "# Task 6: Create a reproducible simulation matrix\n",
    "Initialize a random number generator with a fixed seed. Create a 2D array named sim with shape (1000, 6) representing 1000 trials for 6 scenarios. Use a normal distribution with mean 0 and standard deviation 1. After creating the array, print its shape, dtype, and the first three rows to confirm the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcddfe0-206d-4336-a783-266cf55fc072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 6)\n",
      "Data Type: float64\n",
      "[[ 0.12573022 -0.13210486  0.64042265  0.10490012 -0.53566937  0.36159505]\n",
      " [ 1.30400005  0.94708096 -0.70373524 -1.26542147 -0.62327446  0.04132598]\n",
      " [-2.32503077 -0.21879166 -1.24591095 -0.73226735 -0.54425898 -0.31630016]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "sim = rng.normal(loc=0, scale=1, size=(1000, 6))\n",
    "\n",
    "print(f\"Shape: {sim.shape}\")\n",
    "print(f\"Data Type: {sim.dtype}\")\n",
    "print(sim[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab783d-59a1-4135-b0fc-8a9d7f40b57c",
   "metadata": {},
   "source": [
    "# Task 7: Apply broadcasting for scenario adjustments\n",
    "Create a 1D array named scenario_shift of length 6 containing small offsets such as [-0.3, -0.1, 0.0, 0.1, 0.2, 0.4]. Use broadcasting to add these offsets to sim and store the result in adjusted_sim. Verify that adjusted_sim has the same shape as sim and that the mean of each column changes in the direction of the offsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9abe2052-8cd2-45a1-b375-6db4ae8eb81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape match: True ((1000, 6))\n",
      "Shift vector:    [-0.3 -0.1  0.   0.1  0.2  0.4]\n",
      "Actual mean change: [-0.3 -0.1  0.   0.1  0.2  0.4]\n"
     ]
    }
   ],
   "source": [
    "scenario_shift = np.array([-0.3, -0.1, 0.0, 0.1, 0.2, 0.4])\n",
    "adjusted_sim = sim + scenario_shift\n",
    "\n",
    "shape_match = adjusted_sim.shape == sim.shape\n",
    "\n",
    "original_means = sim.mean(axis=0)\n",
    "adjusted_means = adjusted_sim.mean(axis=0)\n",
    "mean_diffs = adjusted_means - original_means\n",
    "\n",
    "print(f\"Shape match: {shape_match} ({adjusted_sim.shape})\")\n",
    "print(f\"Shift vector:    {scenario_shift}\")\n",
    "print(f\"Actual mean change: {np.round(mean_diffs, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d225b-4b31-4991-bcf9-6edb29148946",
   "metadata": {},
   "source": [
    "# Task 8: Rank scenarios with sorting and partitioning\n",
    "Compute the mean outcome per scenario from adjusted_sim and store it in a 1D array named scenario_means. Use np.argsort to get the ranking of scenarios from lowest to highest. Then use np.partition to identify the top two scenario means without fully sorting the array. Confirm that the top two values from partition match the two largest values from a full sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e6b281-2637-4d33-8d72-bb19bf11889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario Means: [-0.336 -0.05   0.019  0.064  0.195  0.4  ]\n",
      "Ranking (Indices): [0 1 2 3 4 5]\n",
      "Top 2 (Partition): [0.19477725 0.39966337]\n",
      "Top 2 (Full Sort): [0.19477725 0.39966337]\n",
      "Verification Match: True\n"
     ]
    }
   ],
   "source": [
    "scenario_means = adjusted_sim.mean(axis=0)\n",
    "rank_indices = np.argsort(scenario_means)\n",
    "\n",
    "top_two_partition = np.partition(scenario_means, -2)[-2:]\n",
    "full_sort_top_two = np.sort(scenario_means)[-2:]\n",
    "\n",
    "print(f\"Scenario Means: {np.round(scenario_means, 3)}\")\n",
    "print(f\"Ranking (Indices): {rank_indices}\")\n",
    "print(f\"Top 2 (Partition): {np.sort(top_two_partition)}\") \n",
    "print(f\"Top 2 (Full Sort): {full_sort_top_two}\")\n",
    "print(f\"Verification Match: {np.allclose(np.sort(top_two_partition), full_sort_top_two)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ce846-df7d-49e6-bdd1-b5d930af9e4e",
   "metadata": {},
   "source": [
    "# Task 9: Controlled randomness and reproducibility\n",
    "Generate a second simulation matrix sim_2 using the same seed and confirm that it matches sim exactly. Then generate a third matrix sim_3 with a different seed and confirm that it differs. Include a short check such as comparing equality counts or using np.allclose to verify the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c286cce2-34fe-4f6e-89ef-7d8e9291a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim and Sim2 match: True\n",
      "Sim and Sim3 match: False\n",
      "Equality counts: 0\n"
     ]
    }
   ],
   "source": [
    "rng_same = np.random.default_rng(seed=0)\n",
    "sim_2 = rng_same.normal(loc=0, scale=1, size=(1000, 6))\n",
    "\n",
    "rng_diff = np.random.default_rng(seed=16)\n",
    "sim_3 = rng_diff.normal(loc=0, scale=1, size=(1000, 6))\n",
    "\n",
    "match_1_2 = np.array_equal(sim, sim_2)\n",
    "match_1_3 = np.array_equal(sim, sim_3)\n",
    "\n",
    "equal_elements_3 = np.sum(sim == sim_3)\n",
    "\n",
    "print(f\"Sim and Sim2 match: {match_1_2}\")\n",
    "print(f\"Sim and Sim3 match: {match_1_3}\")\n",
    "print(f\"Equality counts: {equal_elements_3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b578536-d94d-43e0-8546-9be6ddcf21d7",
   "metadata": {},
   "source": [
    "# Task 10: Build a validation report (Part 2)\n",
    "Create a small report dictionary with keys shape, scenario_means, top_two_indices, and top_two_values. Convert this report into a readable string and print it. Include at least one validation statement, such as confirming that scenario_means has length 6 and that the top_two_indices list has length 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fdef6f6-483f-4a76-a3ac-6e89667abf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix Shape:       (1000, 6)\n",
      "Scenarios Count:    6\n",
      "\n",
      "VALIDATION\n",
      "- Scenario Means Length (6):  PASS\n",
      "- Top Two Indices Length (2): PASS\n",
      "\n",
      "RESULTS\n",
      "Scenario Means:\n",
      "[-0.336, -0.05 ,  0.019,  0.064,  0.195,  0.4  ]\n",
      "\n",
      "Top Performing Scenarios:\n",
      "- Indices: [4, 5]\n",
      "- Values:  [0.195, 0.4]\n",
      "------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_two_values = np.sort(top_two_partition).tolist()\n",
    "top_two_indices = rank_indices[-2:].tolist()\n",
    "\n",
    "report_sim = {\n",
    "    \"shape\": adjusted_sim.shape,\n",
    "    \"scenario_means\": scenario_means.tolist(),\n",
    "    \"top_two_indices\": top_two_indices,\n",
    "    \"top_two_values\": top_two_values\n",
    "}\n",
    "\n",
    "valid_means_len = len(report_sim[\"scenario_means\"]) == 6\n",
    "valid_top_len = len(report_sim[\"top_two_indices\"]) == 2\n",
    "\n",
    "final_report = f\"\"\"\n",
    "Matrix Shape:       {report_sim['shape']}\n",
    "Scenarios Count:    {len(report_sim['scenario_means'])}\n",
    "\n",
    "VALIDATION\n",
    "- Scenario Means Length (6):  {'PASS' if valid_means_len else 'FAIL'}\n",
    "- Top Two Indices Length (2): {'PASS' if valid_top_len else 'FAIL'}\n",
    "\n",
    "RESULTS\n",
    "Scenario Means:\n",
    "{np.array2string(np.array(report_sim['scenario_means']), precision=3, separator=', ')}\n",
    "\n",
    "Top Performing Scenarios:\n",
    "- Indices: {report_sim['top_two_indices']}\n",
    "- Values:  {np.round(report_sim['top_two_values'], 3).tolist()}\n",
    "------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "print(final_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
